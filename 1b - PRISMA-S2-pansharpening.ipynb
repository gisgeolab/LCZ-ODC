{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c190cc3e-c838-48da-8ad3-d15d71d4343c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<u><strong>Authors:</strong></u> <b>Alberto Vavassori</b> (alberto.vavassori@polimi.it), <b>Emanuele Capizzi</b> (emanuele.capizzi@mail.polimi.it) - 2024 - Politecnico di Milano, Italy <br>\n",
    "Developed within the LCZ-ODC project, funded by the Italian Space Agency (agreement n. 2022-30-HH.0).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186467ce-e465-445a-b146-9bf2deff3021",
   "metadata": {},
   "source": [
    "# Pan-sharpening of Sentinel-2 imagery with PRISMA panchromatic band"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d346af8-1911-4c21-b52a-2aee03af3e94",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This Notebook contains examples of **pan-sharpening methods applied to multispectral Sentinel-2 images** ([Loncan et al. 2015<sup>1</sup>](#1)), using the panchromatic band of the closest (in time) PRISMA image. Thus, super-resolution is achieved through the fusion of Sentinel-2 and PRISMA images.\n",
    "\n",
    "Pansharpening methods are implemented in the `methods.py` file. Functions are adapted to the PRISMA/Sentinel-2 imagery context from a dedicated GitHub Repository[<sup>2</sup>](#2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce9f6a-131e-4e6c-bf12-6e1a506ff17a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Sentinel-2 data specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d6a02-5e70-4251-858c-825f43706be3",
   "metadata": {},
   "source": [
    "Information about Sentinel-2 specifications can be found in the mission overview website[<sup>3</sup>](#3).\n",
    "\n",
    "Specifically, Sentinel-2 carries an optical instrument payload that samples 13 spectral bands in the range 400 - 2400 nm.\n",
    "\n",
    "| Band | Cube | Central wavelength [nm] | Spatial Resolution [m] |\n",
    "| :---: | :---: | :----: | :---: |\n",
    "| B1 | VNIR | 443 | 60 |\n",
    "| B2 | VNIR | 490 | 10 |\n",
    "| B3 | VNIR | 560 | 10 |\n",
    "| B4 | VNIR | 665 | 10 |\n",
    "| B5 | VNIR | 705 | 20 |\n",
    "| B6 | VNIR | 740 | 20 |\n",
    "| B7 | VNIR | 783 | 20 |\n",
    "| B8a | VNIR/SWIR | 865 | 20 |\n",
    "| B9 | VNIR/SWIR | 940 | 60 |\n",
    "| B11 | SWIR | 1610 | 20 |\n",
    "| B12 | SWIR | 2190 | 20 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f12081-311a-499b-911f-2fbafdb0c6f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### PRISMA data specifications\n",
    "\n",
    "Information about the spectral ranges of the hyperspectral and panchromatic data is available within the PRISMA product specification document[<sup>4</sup>](#4).\n",
    "\n",
    "Specifically, spatial and spectral resolutions of the Hyperspectral (HS) - including Visible Near Infrared (VNIR) and Short Wave Infrared (SWIR) - and Panchromatic (PAN) bands are the following:\n",
    "\n",
    "| Sensor | Cube | Spectral Range [nm] | Spatial Resolution [m] | #Bands |\n",
    "| :---: | :---: | :----: | :---: | :---: |\n",
    "| HS | VNIR | 400 - 700 | 30 | 66 |\n",
    "| HS | SWIR | 920 - 2505 | 30 | 171 |\n",
    "| PAN | PAN | 400 - 700 | 5 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cbf67c-1278-4bd9-a4b1-c07939b49a73",
   "metadata": {},
   "source": [
    "### Resources\n",
    "    \n",
    "<span id=\"1\">[<sup>1</sup>Loncan, L. et al. «Hyperspectral Pansharpening: A Review». *IEEE Geoscience and Remote Sensing Magazine* 2015, 3(3), 1879–1900. doi: 10.1109/MGRS.2015.2440094](https://ieeexplore.ieee.org/document/7284770)</span><br>\n",
    "<span id=\"2\">[<sup>2</sup>GitHub Repo for multispectral imagery pansharpening](https://github.com/codegaj/py_pansharpening)</span><br>\n",
    "<span id=\"3\">[<sup>3</sup>Sentinel-2 Mission Overview](https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2/overview)</span><br>\n",
    "<span id=\"4\">[<sup>4</sup>PRISMA Product Specifications](http://prisma.asi.it/missionselect/docs/PRISMA%20Product%20Specifications_Is2_3.pdf)</span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687cb892-5fda-485c-9f49-4d5b4860ed33",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <a id='TOC_TOP'></a>Notebook content\n",
    "\n",
    "</div>\n",
    "    \n",
    " 1. [Libraries and Data Preparation](#sec1)\n",
    " 2. [Component Substitution Based Pansharpening](#sec2)  \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fff8ef-c677-4d0f-8e77-aec9e4079763",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "## <a id='sec1'></a>&#x27A4; 1. Libraries and Data Preparation\n",
    "\n",
    "[Back to top](#TOC_TOP)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4efff-67e2-4a32-b362-c268d369906a",
   "metadata": {},
   "source": [
    "### Import useful libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453cc418-95af-43c4-a16d-59d57b292684",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> Make sure you have the following libraries installed in your working environment:\n",
    "</div>\n",
    "\n",
    "- `h5py`\n",
    "- `sklearn`\n",
    "- `ipyleaflet`\n",
    "- `ipywidgets`\n",
    "- `opencv` (i.e. `cv2`) -> install with `pip install opencv-python`\n",
    "- `leafmap` -> install with `pip install -U leafmap`\n",
    "\n",
    "Common libraries are also required (e.g. `numpy`, `rasterio`, `matplotlib`, `pandas`, `geopandas`, `shapely`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed774f8c-9c44-4c28-8971-f7cea81ebd30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show_hist\n",
    "from rasterio.warp import reproject, Resampling\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image\n",
    "import ipywidgets as widgets\n",
    "from sklearn.decomposition import PCA\n",
    "import geopandas as gpd\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import cv2\n",
    "from shapely.geometry import Polygon\n",
    "from rasterio import mask\n",
    "from shapely.geometry import box\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, DrawControl, LayersControl, Rectangle\n",
    "import leafmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae7fe6-9138-48d5-b7c7-cb4f6340880c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import functions and set auto-reload\n",
    "from methods import *\n",
    "from metrics import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7964c-fc3a-4628-88fa-36b6fffc290b",
   "metadata": {},
   "source": [
    "### Date selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7da27-8776-42f0-9b83-35397851da08",
   "metadata": {},
   "source": [
    "Here it is possible to select the Sentinel-2 and PRISMA image acquisition dates. Pansharpening will be performed only to the selected Sentinel-2 image, using the selected PRISMA panchromatic band."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3cb053-0beb-41fd-a979-54509622c613",
   "metadata": {},
   "source": [
    "Import the PRISMA image and extract its extent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30a130-ea5e-46b8-acdb-f3cfd01945a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_prisma_w = widgets.Dropdown(\n",
    "    options = ['2023-02-09', '2023-03-22', '2023-04-08', '2023-06-17', '2023-07-10', '2023-08-08'],\n",
    "    value = '2023-02-09',\n",
    "    description = 'PRISMA date:',\n",
    "    disabled = False,\n",
    "    layout = {'width': 'max-content'},\n",
    "    style = {'description_width': 'initial'}\n",
    ")\n",
    "date_prisma_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fdc4b9-3ea6-4aab-a61d-9db29652fb1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel_prisma_date = date_prisma_w.value\n",
    "print(f\"The selected date is {sel_prisma_date}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b89ebc-0cb1-4b94-96c8-d582d06ff61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prisma_path = 'coregistered/' + sel_prisma_date.replace('-', '') + '/'\n",
    "prisma_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea619272-3abe-426c-8622-7cd75124f18a",
   "metadata": {},
   "source": [
    "Import the Sentinel-2 image and extract its extent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800849a-36e9-4a12-890b-61d0b12e5458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_s2_w = widgets.Dropdown(\n",
    "    options = ['2023-02-10', '2023-03-22', '2023-04-26', '2023-06-25', '2023-07-10', '2023-08-19'],\n",
    "    value = '2023-02-10',\n",
    "    description = 'Sentinel-2 date:',\n",
    "    disabled = False,\n",
    "    layout = {'width': 'max-content'},\n",
    "    style = {'description_width': 'initial'}\n",
    ")\n",
    "date_s2_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090e2da-7ec5-430f-9ca9-38f8f76cf587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel_s2_date = date_s2_w.value\n",
    "print(f\"The selected date is {sel_s2_date}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11eb9f0-4a9d-4e5c-b777-a34bca7203cd",
   "metadata": {},
   "source": [
    "### Selection of the area of interest (AOI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b4aa8-8469-4a95-a151-f6684ec522f6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> Pansharpening will only be carried out in the selected area. \n",
    "\n",
    "**Note that, considering the limited number of Sentinel-2 bands in comparison with PRISMA, pansharpening can be carried out in a larger area of interest**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b0e96-1ad7-4371-aab8-ec248fdd2f87",
   "metadata": {},
   "source": [
    "Import the polygon representing the area of interest. (A new polygon can also be created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251624a8-e7ce-42bd-9c87-4347fe791a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "polygon = gpd.read_file('./coregistered/' + sel_prisma_date.replace('-', '') + '/aoi_s2.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef37125-ec8a-4230-b669-78690d85f799",
   "metadata": {},
   "source": [
    "### Import the (Sentinel-2) MS and (PRISMA) PAN bands and clip to the AOI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e50f8-7aff-4dfe-ab16-9d1f30d61f6f",
   "metadata": {},
   "source": [
    "The co-registered bands of the HS (VNIR) and PAN cubes are imported and clipped to the selected AOI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234471fd-7bc1-4419-a907-17b17343be56",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> Only the bands of the VNIR are used for pansharpening, since they cover the same region of the elecromagnetic spectrum as the PAN band. Accordingly, the SWIR bands will not be sharpened to the PAN resolution.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e2b2e-ced2-4761-9175-e6b82923bd47",
   "metadata": {},
   "source": [
    "Set the paths of the panchromatic PRISMA band `pan_full` and multispectral Sentinel-2 bands `hs_full` (coregistered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c659166-24a6-429a-b98e-d40df264b3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pan_full = prisma_path + 'PR_pan_' + sel_prisma_date.replace('-', '') + '_5m.tif'\n",
    "hs_full = prisma_path + 'S2_' + sel_s2_date.replace('-', '') + '_20m_all_bands_clip.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e1e6b-df96-48ae-b037-a72f39d92c1b",
   "metadata": {},
   "source": [
    "Set the path and name of the same images clipped to the selected AOI (`pan_path` and `hs_path`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c6240-e3e5-4b58-ba88-4f22a18cbad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pan_path = prisma_path + 'pan_s2.tif'\n",
    "hs_path = prisma_path + 'hs_s2.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e6276c-0020-440c-bc80-a65f9d266859",
   "metadata": {},
   "source": [
    "Call the function `clip_pan_hs` defined in `methods.py` to clip the Sentinel-2 and PAN bands to the AOI and save them to GeoTIFF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222f2b5-a653-40b8-b12d-7145eceb232e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip_pan_hs(hs_full, pan_full, polygon, hs_path, pan_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6fd5f-bd5c-4c1e-b7ce-70959d3b83f3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<span>&#x2714;</span>\n",
    "<a id='libraries'></a>\n",
    "The VNIR and PAN bands have been clipped to the AOI and saved to GeoTIFF files.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fdc445-319b-4be3-bfce-29c8d734f643",
   "metadata": {},
   "source": [
    "### Image preparation for pansharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2d75b-d47d-4278-a61e-494f0015f2bb",
   "metadata": {},
   "source": [
    "Before applying the pansharpening methods, the Sentinel-2 bands have to be upsampled to the same resolution of the PAN band, and possibly all-zero value bands have to be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135fb348-1929-4d0e-aa4b-4fc0647cdbb9",
   "metadata": {},
   "source": [
    "Open the clipped images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dec33b-6fc5-4cd4-b412-a1dc9f04ac52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(pan_path) as src:\n",
    "    pan_data = src.read()\n",
    "    src_meta = src.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93402b75-c8ea-4c56-9c0f-5379c2e83b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(hs_path) as src:\n",
    "    hs_data = src.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7781e-0805-410a-a03f-c250f60ee584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "band_threshold = 1e-8\n",
    "hs_data = hs_data[~np.all(hs_data <= band_threshold, axis=(1,2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93db94-9c62-43cd-bf94-ca173ef78353",
   "metadata": {},
   "source": [
    "Extract the number of VNIR bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719b430-0667-45da-8f4c-06a704b6012e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_bands = hs_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9516fcbf-f093-4a11-8144-50ff430c1499",
   "metadata": {},
   "source": [
    "Set the target resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc837e1-9dc9-429d-ba61-ce05cd29b9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dst_resolution = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c34253-58da-4356-a32e-e56b0717811e",
   "metadata": {},
   "source": [
    "Select the resampling method: this will be used to interpolate the Sentinel-2 bands to the same resolution as PAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a59a5-6de5-49d1-959f-1234f83a5bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resampling_methods = { \"nearest\": Resampling.nearest,\n",
    "                      \"bilinear\": Resampling.bilinear,\n",
    "                      \"cubic\": Resampling.cubic,\n",
    "                      \"cubic_spline\": Resampling.cubic_spline,\n",
    "                      \"lanczos\": Resampling.lanczos,\n",
    "                      \"average\": Resampling.average\n",
    "}\n",
    "\n",
    "resampling_methods_list = list(resampling_methods.keys())\n",
    "\n",
    "resampling_w = widgets.Dropdown(\n",
    "    options=resampling_methods_list,\n",
    "    value='bilinear',\n",
    "    description='Method:',\n",
    "    disabled=False,\n",
    ")\n",
    "resampling_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177904c-c299-41df-b4b1-59a39f575d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dst_meta = src_meta.copy()\n",
    "dst_meta.update({\n",
    "    'height': pan_data.shape[1],\n",
    "    'width': pan_data.shape[2],\n",
    "    'transform': rio.Affine(dst_resolution, 0, src.bounds.left, 0, -dst_resolution, src.bounds.top),\n",
    "    'dtype' : 'float32',\n",
    "    'count': n_bands\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00fb61-5262-4131-acdc-7d7456f3cea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Resampling using {resampling_w.value} done\")\n",
    "resampled_hs = np.zeros((dst_meta['count'], src_meta['height'], src_meta['width']), dtype=hs_data.dtype)\n",
    "reproject(hs_data,resampled_hs,src_transform=src.transform,src_crs=src.crs, dst_transform=dst_meta['transform'], dst_crs=src.crs, resampling=resampling_methods[resampling_w.value]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd5f4c8-a525-4ecf-ab09-8d218d577aa1",
   "metadata": {},
   "source": [
    "Save the Sentinel-2 bands upsampled at 5m resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fc0f1-6da6-45e2-b50b-60a1a2a1390f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hs_5m_path = prisma_path + \"hs_s2_5m_NN.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e37ad-c670-4a23-a4a4-bf28bb2af8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(hs_5m_path, 'w', **dst_meta) as dst:\n",
    "    dst.write(resampled_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb108cf-3474-4d40-bc95-f96df1fe9240",
   "metadata": {},
   "source": [
    "Finally, open the upsampled Sentinel-2 image at 5m resolution and remove the bands with all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdff41f-1a95-44b8-b28b-9fb20bf573d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(hs_5m_path) as src:\n",
    "    hs_5m_data = src.read()\n",
    "    \n",
    "band_threshold = 1e-8\n",
    "hs_5m_data = hs_5m_data[~np.all(hs_5m_data <= band_threshold, axis=(1,2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027cb00-4b44-46c4-958c-b060c7245e7b",
   "metadata": {},
   "source": [
    "The number of bands without all zeros is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a4e0f-601c-4500-b9c9-1c7917114185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hs_5m_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61dbdd9-a6b5-4ced-b545-6c2cb5c83105",
   "metadata": {},
   "source": [
    "Update the metadata of the image. This metadata will be used to export the pansharpened images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628df46f-2fe8-4b5e-be48-bc5a4eafa013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dst_meta.update({\n",
    "    'height': int(src.height * src.transform[0] / dst_resolution),\n",
    "    'width': int(src.width * src.transform[0] / dst_resolution),\n",
    "    'transform': rio.Affine(dst_resolution, 0, src.bounds.left, 0, -dst_resolution, src.bounds.top),\n",
    "    'dtype' : 'float32',\n",
    "    'count': hs_5m_data.shape[0]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8f6b5-c086-4dd4-abad-5abc2643287b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='sec2'></a>&#x27A4; 2. Component Substitution Based Pansharpening\n",
    "\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393a347-0e20-4d25-a264-73db0f61c257",
   "metadata": {},
   "source": [
    "In this part of the Notebook, two Component Substitution (CS) based approaches are implemented for Sentinel-2 image pansharpening, namely the **Principal Component Analysis (PCA)** and **Gram-Schmidt (GS)** methods. An adaptive version of the GS is also implemented, namely **Gram-Schmidt Adaptive (GSA)** ([Aiazzi et al. 2007<sup>8</sup>](#8)).\n",
    "\n",
    "These methods rely upon the projection of the higher spectral resolution image into another space, in order to separate spatial and spectral information. The transformed data are sharpened by substituting the component that containes the spatial information with the PAN image. The greater the correlation between the PAN image and the replaced component, the less spectral distortion will be introduced by the fusion approach. The fusion process is completed by applying the inverse spectral transformation to obtain the fused image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f187211-04ce-4636-a65e-d337346a75b9",
   "metadata": {},
   "source": [
    "The general equation can be expressed as follows:\n",
    "\n",
    "$\\hat{H}_k = \\tilde{H}_k + G_k (P-I_L) \\quad k = 1, ..., N$\n",
    "\n",
    "* $\\hat{H}_k$ is the HS pansharpened image;\n",
    "* $\\tilde{H}_k$ is the HS image interpolated at PAN scale;\n",
    "* $P$ is the PAN image;\n",
    "* $G_k$ are the gain coefficients;\n",
    "* $I_L$ is the so-called intensity component;\n",
    "\n",
    "while $k$ denotes the k-th band ($N$ is the number of bands).\n",
    "\n",
    "$G_k$ and $I_L$ are computed differently depending on the employed method.\n",
    "\n",
    "$I_L$ can be expressed as $I_L = \\sum_{i=1}^{N} w_i \\tilde{H}_i$, but different formulations exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39062e5d-7f47-424d-b1ec-7b009d44c1d9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> Note about the input data shape for pansharpening functions:\n",
    "</div>\n",
    "\n",
    "Input data must be provided in the following order: `(n_bands, height, width)`.\n",
    "\n",
    "Nonetheless, in order to be saved as GeoTIFF in rasterio the order must be the following: `(height, width, n_bands)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082d9ad-8208-44d4-85af-f679fb9967c4",
   "metadata": {},
   "source": [
    "### **PCA**-based pansharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c996e2a-fc01-4004-9a67-49af87bed398",
   "metadata": {},
   "source": [
    "The hypothesis underlying the application of PCA to pansharpening is that the spatial information (shared by all the channels) is concentrated in the first PC, while the spectral information specific to each single band) is accounted for the other PCs.\n",
    "\n",
    "The vectors $w_i$ and $G_k$ of coefficient vectors are derived by the PCA procedure applied to the HS image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ac131-b261-49d1-99cf-e19e2aba54c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Launch the algorithm\n",
    "PCA_pansharpened, variance_ratios, pc_comp = pan_pca(pan_data, hs_5m_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5173ffd-1182-4aef-aacd-0384ffa61d7a",
   "metadata": {},
   "source": [
    "The higher the explained variance of the first Principal Component, the more reliable is the method.\n",
    "It is hereafter possible to display the explained variance ratio of the first 10 Principal Components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4eca6-ba6b-49c3-9b31-f8c4f5358415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_bar_components = 4 #Change depending on the number of PC to be plotted\n",
    "pc_names = ['PC' + str(i) for i in range(1, x_bar_components+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63105b43-e698-4e79-9b61-5eeb35602229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(range(x_bar_components), variance_ratios[0:x_bar_components], marker = 'o')\n",
    "# set the x-axis labels\n",
    "plt.xticks(range(x_bar_components), pc_names)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb267f-45b3-449b-ac4d-c70e5a376859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to file\n",
    "with rio.open(prisma_path + 'pansharpened_s2_PCA.tif', 'w', **dst_meta) as dst:\n",
    "    dst.write(PCA_pansharpened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3537b4-25d4-42b0-9c1b-346ad2b38a40",
   "metadata": {},
   "source": [
    "### **GS**-based pansharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16889ebe-18f5-41f3-8179-50e1d9d363ed",
   "metadata": {},
   "source": [
    "The fusion process starts by using, as the component, a synthetic low resolution PAN image $I_L$ at the same spatial resolution as the HS image. A complete orthogonal decomposition is then performed, starting with that component. The pansharpening procedure is completed by substituting that component with the PAN image, and inverting the decomposition.\n",
    "\n",
    "Gain coefficients are computed as follows:\n",
    "\n",
    "$G_k = \\frac{cov(\\tilde{H}_k, I_L)}{var(I_L)}$\n",
    "\n",
    "while the weights:\n",
    "\n",
    "$w_i = \\frac{1}{N}$\n",
    "\n",
    "meaning that the intensity component is computed as a mean of the HS bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3f25a-5a0c-485c-87fa-577901a08806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Launch the algotithm\n",
    "GS_pansharpened = pan_GS(pan_data, hs_5m_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ec7ae-54a6-4241-b7ac-58fb4a819f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to file\n",
    "with rio.open(prisma_path + 'pansharpened_s2_GS.tif', 'w', **dst_meta) as dst:\n",
    "    dst.write(GS_pansharpened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d99a7c-534e-45a4-b575-5a75796ea99a",
   "metadata": {},
   "source": [
    "### **GSA**-based pansharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c27f9f-461f-43b8-b2bf-73c0b86c38cc",
   "metadata": {},
   "source": [
    "In adaptive version of the GS method, a linear regression between PAN and HS bands is performed. A synthetic intensity having a minimum mean-square error with respect to the reduced PAN, is computed. Accordingly, the weights $w_i$ are estimated by means of a *linear regression algorithm*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159774c-845f-48ca-bd4d-9cd516f741a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Launch the algorithm\n",
    "GSA_pansharpened = pan_GSA(pan_data, hs_data, hs_5m_data, 'local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd7c77-5292-4108-b38b-30e43f62d051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to file\n",
    "with rio.open(prisma_path + 'pansharpened_s2_GSA.tif', 'w', **dst_meta) as dst:\n",
    "    dst.write(GSA_pansharpened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3e26d7-ff4a-41f6-8622-21c32a53a816",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='sec3'></a>&#x27A4; 3. Pansharpening Quality Assessment\n",
    "\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155c772-e4f4-464b-baf3-5ed7a9402ffd",
   "metadata": {},
   "source": [
    "### Visual inspection of the pansharpening quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a1d20-fd83-4966-ab39-6a058c60bfc2",
   "metadata": {},
   "source": [
    "In this part of the Notebook, it is possible to export the RGB pansharpened images and inspect visually the result quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ac9c4-f3ed-4804-9c65-2bf4b6057e32",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<span>&#x2714;</span>\n",
    "<a id='libraries'></a>\n",
    "First, select which of the three pansharpened images you want to export and visualize.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfb290-9662-452e-ad9a-5d96343160e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sw = widgets.RadioButtons(\n",
    "    options=['Principal Component Analysis', 'Gram-Schmidt', 'Gram-Schmidt Adaptive'],\n",
    "    description='Image to visualize',\n",
    "    disabled=False,\n",
    "    value='Gram-Schmidt Adaptive'\n",
    ")\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed940400-f0af-4325-bd15-a4723f01ecf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if sw.value == 'Principal Component Analysis':\n",
    "    image_pansharpened = PCA_pansharpened\n",
    "elif sw.value == 'Gram-Schmidt':\n",
    "    image_pansharpened = GS_pansharpened\n",
    "else: image_pansharpened = GSA_pansharpened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983a5ba-4742-4d08-bf72-b28e0c36b3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update the number of bands to 3 before running the function\n",
    "dst_meta['count'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b71627-be68-4845-aa6e-8e67bfbe5344",
   "metadata": {},
   "source": [
    "The following function will create RGB images from the pansharpened and the original HS image. This is intended for both easier visualization in a GIS software and for convertion to PNG image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80867cce-90fa-4d66-b97d-80b2d307a622",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> In the following line of code, change the corresponding channels for red, green and blue. Default values are red=32, green=22, blue=11 for PRISMA imagery, but other values can be provided for the visualization.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59cae0-4e40-461f-9b2f-5980b2cb0f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_pansh, data_hs = convert_to_RGB(image_pansharpened, hs_5m_data, dst_meta, 1, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeda7bc-888f-47e0-8f91-1953da747c1e",
   "metadata": {},
   "source": [
    "Export the created RGB image to JPG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4970d-1f48-4eaa-8097-ffe1f661aa22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matplotlib.image.imsave('img_pansh.jpg', data_pansh)\n",
    "matplotlib.image.imsave('image_orig.jpg', data_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c843fb-1d26-4e16-b03c-fd43e3602758",
   "metadata": {},
   "source": [
    "Display an interactive visualization for easy comparison of the original and pansharpened images in the area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa13b2f-2bc5-4ae2-a5eb-13e4a3681793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_pansh = 'img_pansh.jpg'\n",
    "image_orig = \"image_orig.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1ac9d-fd7d-47c0-b951-cf59c5f869b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "leafmap.image_comparison(\n",
    "    image_orig,\n",
    "    img_pansh,\n",
    "    label1='Original Image',\n",
    "    label2='Pansharpened Image',\n",
    "    starting_position=50,\n",
    "    width=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa1605-5023-4634-b253-4b7d854a1a06",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> If the interactive image does not appear, run again the last code block.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e9dd4-cde2-4013-add1-777eb6cbd2e9",
   "metadata": {},
   "source": [
    "### Quantitative assessment of the pansharpening quality: quality indexes computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04df14e",
   "metadata": {},
   "source": [
    "In this part some metrics are calculated to quantitatively assess the quality of the pansharpened images, following the reduced resolution (RR) approach.\n",
    "RR approach measures the similarity of the fused product to an idea reference, namely the original HS image.\n",
    "Accordingly, the resolutions of the original HS and PAN images are degradated and the fusion is performed on the degraded data.\n",
    "\n",
    "The following quality measures are used:\n",
    "1. *Spectral Angle Mapper (SAM)* that measures spectral quality;\n",
    "2. *Erreur Relative Globale Adimensionnelle de Synthése (ERGAS)* which is a global adimensional quality index based on the RMSE;\n",
    "3. *Spatial Correlation Coefficient (SCC)* that measure spatial quality;\n",
    "4. *Peak Signal-to-Noise Ratio (PSNR)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6f437",
   "metadata": {},
   "source": [
    "Import the pansharpened images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01813eff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pansharpened_img_GSA = 'pansharpened_GSA.tif'\n",
    "pansharpened_img_GS = 'pansharpened_GS.tif'\n",
    "pansharpened_img_PCA = 'pansharpened_PCA.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01679ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(pansharpened_img_GSA) as src_pansharpened_gsa:\n",
    "    # Read the data from the red, green, and blue bands\n",
    "    pansharpened_gsa = src_pansharpened_gsa.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c3560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(pansharpened_img_GS) as src_pansharpened_gs:\n",
    "    # Read the data from the red, green, and blue bands\n",
    "    pansharpened_gs = src_pansharpened_gs.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582477c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(pansharpened_img_PCA) as src_pansharpened_pca:\n",
    "    # Read the data from the red, green, and blue bands\n",
    "    pansharpened_pca = src_pansharpened_pca.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074ea06",
   "metadata": {},
   "source": [
    "The first step is to degrade the pansharpened image to the original HS resolution, i.e. 30 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde21fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "degrade_resolution = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf0fc95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set metadata of the degraded image\n",
    "dst_meta_downgrade = dst_meta.copy()\n",
    "dst_meta_downgrade.update({\n",
    "    'height': int(src_pansharpened_gsa.height * src_pansharpened_gsa.transform[0] / degrade_resolution),\n",
    "    'width': int(src_pansharpened_gsa.width * src_pansharpened_gsa.transform[0] / degrade_resolution),\n",
    "    'transform': rio.Affine(degrade_resolution, 0, src_pansharpened_gsa.bounds.left, 0, -degrade_resolution, src_pansharpened_gsa.bounds.top),\n",
    "    'dtype' : 'float32',\n",
    "    'count': n_bands\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4cc68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#GSA\n",
    "downgraded_pansharp_gsa = np.zeros((src_pansharpened_gsa.count, dst_meta_downgrade['height'], dst_meta_downgrade['width']), dtype=pansharpened_gsa.dtype)\n",
    "reproject(pansharpened_gsa,downgraded_pansharp_gsa,src_transform=src_pansharpened_gsa.transform,src_crs=src_pansharpened_gsa.crs, dst_transform=dst_meta_downgrade['transform'], \n",
    "          dst_crs=src_pansharpened_gsa.crs, resampling=Resampling.bilinear);\n",
    "\n",
    "#GS\n",
    "downgraded_pansharp_gs = np.zeros((src_pansharpened_gsa.count, dst_meta_downgrade['height'], dst_meta_downgrade['width']), dtype=pansharpened_gsa.dtype)\n",
    "reproject(pansharpened_gs,downgraded_pansharp_gs,src_transform=src_pansharpened_gsa.transform,src_crs=src_pansharpened_gsa.crs, dst_transform=dst_meta_downgrade['transform'], \n",
    "          dst_crs=src_pansharpened_gsa.crs, resampling=Resampling.bilinear);\n",
    "\n",
    "#PCA\n",
    "downgraded_pansharp_pca = np.zeros((src_pansharpened_gsa.count, dst_meta_downgrade['height'], dst_meta_downgrade['width']), dtype=pansharpened_gsa.dtype)\n",
    "reproject(pansharpened_pca,downgraded_pansharp_pca,src_transform=src_pansharpened_gsa.transform,src_crs=src_pansharpened_gsa.crs, dst_transform=dst_meta_downgrade['transform'], \n",
    "          dst_crs=src_pansharpened_gsa.crs, resampling=Resampling.bilinear);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c7018-2dc5-4a74-82f9-5f38f6aabbbc",
   "metadata": {},
   "source": [
    "Save the degraded images to GeoTIFF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be44d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gsa_30_path = \"GSA_30m.tif\"\n",
    "gs_30_path = \"GS_30m.tif\"\n",
    "pca_30_path = \"PCA_30m.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd3857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(gsa_30_path, 'w', **dst_meta_downgrade) as dst:\n",
    "    dst.write(downgraded_pansharp_gsa)\n",
    "\n",
    "with rio.open(gs_30_path, 'w', **dst_meta_downgrade) as dst:\n",
    "    dst.write(downgraded_pansharp_gs)\n",
    "    \n",
    "with rio.open(pca_30_path, 'w', **dst_meta_downgrade) as dst:\n",
    "    dst.write(downgraded_pansharp_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f5ac4a",
   "metadata": {},
   "source": [
    "#### 1. Spectral Angle Mapper (SAM)\n",
    "\n",
    "Denote ground truth by $I\\in\\mathbb{R}^{HW\\times C}$ and generated one by $\\hat{I}\\in\\mathbb{R}^{HW\\times C}$,\n",
    "SAM. $\\hat{I}_i, I_i \\in\\mathbb{R}^{C\\times 1}$ stand for the $i$-th row of $\\hat{I}$ and $I$ respectively,\n",
    "then\n",
    "\n",
    "$\\mathrm{SAM}(\\hat{I}, I) = \\frac{1}{HW}\\sum_{i=1}^{HW}\\arccos \\frac{<\\hat{I}_i, I_i>}{||\\hat{I}_i||||I_i||} \\,.\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a4ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The optimum value is 0.\")\n",
    "print(f\"SAM applied on GSA pansharpened image: {sam(downgraded_pansharp_gsa, hs_data):.3f}\")\n",
    "print(f\"SAM applied on GS pansharpened image: {sam(downgraded_pansharp_gs, hs_data):.3f}\")\n",
    "print(f\"SAM applied on PCA pansharpened image: {sam(downgraded_pansharp_pca, hs_data):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86191c5e",
   "metadata": {},
   "source": [
    "#### 2. Erreur Relative Globale Adimensionnelle de Synthése (ERGAS)\n",
    "\n",
    "Denote the ratio of spatial resolution of PAN and LRMS by $\\mathrm{scale}$ (e.g. 6 in this case, going from 5m to 30m), then\n",
    "\n",
    "$\n",
    "\\mathrm{ERGAS}(\\hat{I}, I) = 100*\\mathrm{scale}\\sqrt{\\frac 1C\\sum_{c=1}^C\\left(\\frac{\\mathrm{RMSE}_c}{\\mu_c}\\right)^2}\\,,\n",
    "$\n",
    "\n",
    "where $\\mathrm{RMSE}_c$ is the RMSE between $\\hat{I}_c$ and $I_c$; $\\mu_c$ is mean of $I_c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963cb35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The optimum value is 0.\")\n",
    "print(f\"ERGAS applied on GSA pansharpened image: {ergas(downgraded_pansharp_gsa, hs_data):.3f}\")\n",
    "print(f\"ERGAS applied on GS pansharpened image: {ergas(downgraded_pansharp_gs, hs_data):.3f}\")\n",
    "print(f\"ERGAS applied on PCA pansharpened image: {ergas(downgraded_pansharp_pca, hs_data):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cbf17e",
   "metadata": {},
   "source": [
    "#### 3. Spatial Correlation Coefficient (SCC)\n",
    "\n",
    "$\\hat{I}_c, I_c \\in\\mathbb{R}^{HW}$ stand for the $c$-th column of $\\hat{I}$ and $I$ respectively, then\n",
    "\n",
    "$ \\mathrm{SCC}(\\hat{I}, I) = \\frac 1C\\sum_{c=1}^C\\frac{\\sigma_{\\mathrm{cov}_c}}{\\hat\\sigma_c\\sigma_c} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab20da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The optimum value is 1.\")\n",
    "print(f\"SCC applied on GSA pansharpened image: {scc(downgraded_pansharp_gsa, hs_data):.3f}\")\n",
    "print(f\"SCC applied on GS pansharpened image: {scc(downgraded_pansharp_gs, hs_data):.3f}\")\n",
    "print(f\"SCC applied on PCA pansharpened image: {scc(downgraded_pansharp_pca, hs_data):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee998f8",
   "metadata": {},
   "source": [
    "#### 4. Peak Signal-to-Noise Ratio (PSNR)\n",
    "\n",
    "$\\mathrm{MAX}$ is the dynamic range of the pixel-values, then\n",
    "\n",
    "$\n",
    "\\mathrm{PSNR}(\\hat{I}, I) = 10\\log_{10} \\left(\\frac{\\mathrm{MAX}}{\\mathrm{RMSE}(\\hat{I}, I)}\\right)^2\\,.\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3e28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Higher PSNR is better.\")\n",
    "print(f\"PSNR applied on GSA pansharpened image: {psnr(downgraded_pansharp_gsa, hs_data):.3f}\")\n",
    "print(f\"PSNR applied on GS pansharpened image: {psnr(downgraded_pansharp_gs, hs_data):.3f}\")\n",
    "print(f\"PSNR applied on PCA pansharpened image: {psnr(downgraded_pansharp_pca, hs_data):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b82408-fd45-4a87-b780-7ec7356a9a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c171d57-07cd-4c9b-99f2-1a56e20bf110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
