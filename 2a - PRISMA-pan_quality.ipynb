{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c190cc3e-c838-48da-8ad3-d15d71d4343c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<u><strong>Authors:</strong></u> <b>Alberto Vavassori</b> (alberto.vavassori@polimi.it), <b>Emanuele Capizzi</b> (emanuele.capizzi@mail.polimi.it), <b>Vasil Yordanov</b> (vasil.yordanov@polimi.it) - 2024 - Politecnico di Milano, Italy <br>\n",
    "Developed within the LCZ-ODC project, funded by the Italian Space Agency (agreement n. 2022-30-HH.0).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186467ce-e465-445a-b146-9bf2deff3021",
   "metadata": {},
   "source": [
    "# PRISMA pan-sharpening: quality assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dddfd2-86e3-44f5-87cf-6c77c81f1963",
   "metadata": {},
   "source": [
    "This Notebook implements **quality assessment** of pansharpened PRISMA images ([Dhore and Veena 2015<sup>1</sup>](#1); [Helmy and El-Tawel 2015<sup>2</sup>](#2)). Quality indexes are implemented in the `metrics.py` file. Metrics computation is adopted from a dedicated GitHub Repository[<sup>3</sup>](#3).\n",
    "Quality assessment is carried out following the guidelines of the Wald's protocol[<sup>4</sup>](#4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9504bcb-f90b-4ee0-bece-2a300d00dee8",
   "metadata": {},
   "source": [
    "### Resources\n",
    "<span id=\"1\">[<sup>1</sup>Dhore, A.D. and Veena, C.S. «Evaluation of various pansharpening methods using image quality metrics». In Proceedings of the 2nd International Conference on Electronics and Communication Systems (ICECS), Coimbatore, India, 2015, 871–877.](https://ieeexplore.ieee.org/document/7125039)</span><br>\n",
    "<span id=\"2\">[<sup>2</sup>Helmy, A.K. and El-Tawel, G.S. «An integrated scheme to improve pan-sharpening visual quality of satellite images». *Egyptian Informatics Journal* 2015, 16(1), 121–131. doi: 10.1016/j.eij.2015.02.003](https://www.sciencedirect.com/science/article/pii/S1110866515000079#:~:text=Formula%20of%20ERGAS%3A,N%20represents%20no%20of%20bands)</span><br>\n",
    "<span id=\"3\">[<sup>3</sup>GitHub Repo for pansharpening quality assessment](https://github.com/wasaCheney/IQA_pansharpening_python)</span><br>\n",
    "<span id=\"4\">[<sup>4</sup>Wald, L. et al. «Fusion of satellite images of different spatial resolutions: Assessing the quality of resulting images». *Photogrammetric engineering and remote sensing* 1997, 63(6), 691-699](https://hal.science/hal-00365304/)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6199dd-1bc3-4dec-be44-a8797ddf26e0",
   "metadata": {},
   "source": [
    "### <a id='TOC_TOP'></a>Notebook content\n",
    "\n",
    "</div>\n",
    "    \n",
    " 1. [Libraries and Data Preparation](#sec1)\n",
    " 2. [Visual inspection of the pansharpening quality](#sec2)\n",
    " 3. [Spectral distorsions on the training samples](#sec3)\n",
    " 4. [Quantitative assessment of the pansharpening quality: quality indexes computation](#sec4)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fff8ef-c677-4d0f-8e77-aec9e4079763",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "## <a id='sec1'></a>&#x27A4; 1. Libraries and Data Preparation\n",
    "\n",
    "[Back to top](#TOC_TOP)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4efff-67e2-4a32-b362-c268d369906a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed774f8c-9c44-4c28-8971-f7cea81ebd30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show_hist\n",
    "from rasterio.warp import reproject, Resampling\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image\n",
    "import ipywidgets as widgets\n",
    "from sklearn.decomposition import PCA\n",
    "import geopandas as gpd\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import cv2\n",
    "import json\n",
    "import xml.dom.minidom\n",
    "from shapely.geometry import Polygon\n",
    "from rasterio import mask\n",
    "from shapely.geometry import box\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, DrawControl, LayersControl, Rectangle\n",
    "import leafmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae7fe6-9138-48d5-b7c7-cb4f6340880c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import functions and set auto-reload\n",
    "from methods import *\n",
    "from metrics import *\n",
    "from functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a0b5d-5d45-4f78-bb84-3c0fe9bdc949",
   "metadata": {},
   "source": [
    "### Date selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800e209-e508-4c35-8932-195eaf7fab23",
   "metadata": {},
   "source": [
    "Here it is possible to select the PRISMA image acquisition date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2989be3-ba91-493b-b2ba-bfc935d2c601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_prisma_w = widgets.Dropdown(\n",
    "    options = ['2023-02-09', '2023-03-22', '2023-04-08', '2023-06-17', '2023-07-10', '2023-08-08'],\n",
    "    value = '2023-02-09',\n",
    "    description = 'PRISMA date:',\n",
    "    disabled = False,\n",
    "    layout = {'width': 'max-content'},\n",
    "    style = {'description_width': 'initial'}\n",
    ")\n",
    "date_prisma_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d69bd8-369d-403b-9885-c868dae7413b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel_prisma_date = date_prisma_w.value\n",
    "print(f\"The selected date is {sel_prisma_date}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36448f5-4cda-40c4-8d7e-c968d53df8c8",
   "metadata": {},
   "source": [
    "Number of bands on which pansharpening is performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15533b5-8f65-414f-9877-24856219aafa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_bands = 63"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6975c8-0485-4b83-abfa-dddad6fa24f5",
   "metadata": {},
   "source": [
    "According to the selected date, the folder containing the coregistered images (where the outputs of the Notebook will be saved as well) is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384b423-a0f8-4827-b547-210b13e11107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prisma_path = 'coregistered/' + sel_prisma_date.replace('-', '') + '/'\n",
    "prisma_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589fb8fa-aa30-4582-9262-18f0527c30a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel_prisma_date = date_prisma_w.value\n",
    "selected_prisma_image = prisma_path + 'hs_VNIR_1.tif'\n",
    "selected_prisma_pan = prisma_path + 'pan_1.tif'\n",
    "selected_prisma_image_5m = prisma_path + 'hs_5m_1_nn.tif'\n",
    "\n",
    "print(f\"The selected date is --> {sel_prisma_date}.\")\n",
    "print(f\"The selected PRISMA image is --> {selected_prisma_image}.\")\n",
    "print(f\"The selected PRISMA image (at 5m) is --> {selected_prisma_image_5m}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155c772-e4f4-464b-baf3-5ed7a9402ffd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "## <a id='sec2'></a>&#x27A4; 2. Visual inspection of the pansharpening quality\n",
    "\n",
    "[Back to top](#TOC_TOP)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a1d20-fd83-4966-ab39-6a058c60bfc2",
   "metadata": {},
   "source": [
    "In this part of the Notebook, it is possible to export the RGB pansharpened images and inspect visually the result quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfb290-9662-452e-ad9a-5d96343160e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sw = widgets.RadioButtons(\n",
    "    options=['Principal Component Analysis', 'Gram-Schmidt', 'Gram-Schmidt Adaptive'],\n",
    "    description='Image to visualize',\n",
    "    disabled=False,\n",
    "    value='Gram-Schmidt Adaptive'\n",
    ")\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b05790-2c6e-4152-8116-d83f669133f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if sw.value == 'Principal Component Analysis':\n",
    "    image_pansharpened_path = prisma_path + 'pansharpened_PCA_1.tif'\n",
    "elif sw.value == 'Gram-Schmidt':\n",
    "    image_pansharpened_path = prisma_path + 'pansharpened_GS_1.tif'\n",
    "else: image_pansharpened_path = prisma_path + 'pansharpened_GSA_1.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8d206-9b2d-4cb8-81cc-680ca4525b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_prisma_pan_image = image_pansharpened_path\n",
    "selected_prisma_pan_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ac9c4-f3ed-4804-9c65-2bf4b6057e32",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<span>&#x2714;</span>\n",
    "<a id='libraries'></a>\n",
    "First, select which of the three pansharpened images you want to export and visualize.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7344f9d-4a5f-4c1e-b8e2-3636fa5c801a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# original PRISMA image (30m)\n",
    "with rio.open(selected_prisma_image) as src_hs:\n",
    "    hs_data = src_hs.read()\n",
    "    hs_data_meta = src_hs.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379ca15-8cae-4667-8215-7baca950c336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# panchromatic PRISMA band (5m)\n",
    "with rio.open(selected_prisma_pan) as src_pan:\n",
    "    pan_data = src_pan.read()\n",
    "    pan_data_meta = src_pan.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184392f-bba6-4668-8b30-a81256f0be9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PRISMA image interpolated at 5m (nearest neighbour)\n",
    "with rio.open(selected_prisma_image_5m) as src:\n",
    "    hs_5m_data = src.read()\n",
    "    hs_5m_data_meta = src.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c78cd4-e87f-4a4d-b368-ed4d356ca9cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pansharpened PRISMA image\n",
    "with rio.open(image_pansharpened_path) as src_p:\n",
    "    image_pansharpened = src_p.read()\n",
    "    pansharpened_meta = src_p.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dad9cb-da21-4df0-beb9-69051f1c82f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_pansharpened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983a5ba-4742-4d08-bf72-b28e0c36b3c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update the number of bands to 3 before running the function\n",
    "dst_meta = pansharpened_meta\n",
    "dst_meta['count'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b71627-be68-4845-aa6e-8e67bfbe5344",
   "metadata": {},
   "source": [
    "The following function `convert_to_RGB` will create RGB images from the pansharpened and the original HS image. This is intended for both easier visualization in a GIS software and for convertion to PNG image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59cae0-4e40-461f-9b2f-5980b2cb0f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_pansh, data_hs = convert_to_RGB(prisma_path, image_pansharpened, hs_5m_data, pansharpened_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeda7bc-888f-47e0-8f91-1953da747c1e",
   "metadata": {},
   "source": [
    "Export the created RGB image to JPG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4970d-1f48-4eaa-8097-ffe1f661aa22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if sw.value == 'Principal Component Analysis':\n",
    "    matplotlib.image.imsave(prisma_path + 'validation/' + 'image_pansharpened_PCA.jpg', data_pansh, vmax = 0.5)\n",
    "    matplotlib.image.imsave(prisma_path + 'validation/' + 'image_original.jpg', data_hs, vmax = 0.5)\n",
    "    img_pansh = prisma_path + 'validation/' + 'image_pansharpened_PCA.jpg'\n",
    "    image_orig = prisma_path + 'validation/' + 'image_original.jpg'\n",
    "elif sw.value == 'Gram-Schmidt':\n",
    "    matplotlib.image.imsave(prisma_path + 'validation/' + 'image_pansharpened_GS.jpg', data_pansh, vmax = 0.5)\n",
    "    matplotlib.image.imsave(prisma_path + 'validation/' + 'image_original.jpg', data_hs, vmax = 0.5)\n",
    "    img_pansh = prisma_path + 'validation/' + 'image_pansharpened_GS.jpg'\n",
    "    image_orig = prisma_path + 'validation/' + 'image_original.jpg'\n",
    "elif sw.value == 'Gram-Schmidt Adaptive':\n",
    "    matplotlib.image.imsave(prisma_path + 'validation/' + 'image_pansharpened_GSA.jpg', data_pansh)#, vmax = 0.5\n",
    "    matplotlib.image.imsave(prisma_path + 'validation/' + 'image_original.jpg', data_hs)#, vmax = 0.5\n",
    "    img_pansh = prisma_path + 'validation/' + 'image_pansharpened_GSA.jpg'\n",
    "    image_orig = prisma_path + 'validation/' + 'image_original.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c843fb-1d26-4e16-b03c-fd43e3602758",
   "metadata": {},
   "source": [
    "Display an interactive visualization for easy comparison of the original and pansharpened images in the area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1ac9d-fd7d-47c0-b951-cf59c5f869b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "leafmap.image_comparison(\n",
    "    image_orig,\n",
    "    img_pansh,\n",
    "    label1='Original Image',\n",
    "    label2='Pansharpened Image',\n",
    "    starting_position=50,\n",
    "    width=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa1605-5023-4634-b253-4b7d854a1a06",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> If the interactive image does not appear, run again the last code block.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800df3b-5092-4f80-b0a5-d54f81ccbdc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "## <a id='sec3'></a>&#x27A4; 3. Spectral distorsions on the training samples\n",
    "\n",
    "[Back to top](#TOC_TOP)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30328be9-29d0-424a-956f-0e3a93c1ee50",
   "metadata": {},
   "source": [
    "In this part, the spectral signatures, before and after pansharpening, of the training samples used for LCZ classification are plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e2708-e8f7-4872-abb8-ad2f63fef1c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Open the JSON files to retrieve the PRISMA and Sentinel-2 band central wavelengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8a831-84e5-458f-bcaf-de68f3bb802a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./layers/PRISMA_wvl.json', \"r\") as json_file:\n",
    "    wvl = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ecbf95-3870-46ca-8618-b29ad8ae88c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./layers/S2_wvl.json', \"r\") as json_file:\n",
    "    wvl_s = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b235645-9d07-4471-95d2-0dd60ad08998",
   "metadata": {},
   "source": [
    "Import the geopackages containing pre-defined training samples and the boundary of the area of interest (i.e. the Metropolitan City of Milan):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8483185-4bb5-4fe7-8ecc-2aaa0304a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = './layers/training_samples/training_set_' + sel_prisma_date.replace('-', '') + '.gpkg'\n",
    "cmm_folder = './layers/CMM.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5e1ce-97ef-44e8-b7ea-f2b87fef5374",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = {\n",
    "    2: ['Compact mid-rise', '#D10000'],\n",
    "    3: ['Compact low-rise', '#CD0000'],\n",
    "    5: ['Open mid-rise', '#FF6600'],\n",
    "    6: ['Open low-rise', '#FF9955'],\n",
    "    8: ['Large low-rise', '#BCBCBC'],\n",
    "    101: ['Dense trees', '#006A00'],\n",
    "    102: ['Scattered trees', '#00AA00'],\n",
    "    104: ['Low plants', '#B9DB79'],\n",
    "    105: ['Bare rock or paved', '#545454'],\n",
    "    106: ['Bare soil or sand', '#FBF7AF'],\n",
    "    107: ['Water', '#6A6AFF']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2bd9a-81d8-4a32-baf2-1a491e6e822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, m, shapes = plot_training_samples(training_folder, cmm_folder, legend)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a88bf68-1d67-4142-a75d-65cb80ea79c7",
   "metadata": {},
   "source": [
    "Compute *median*, *mean*, and *standard deviation* of the spectral signatures of the training samples from **PRISMA**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2270c-211b-47e0-8d04-a2e4620c6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_sign_median, spectral_sign_std = compute_spectral_signature(selected_prisma_image, legend, shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a15f15c-09f8-4cbf-8d67-f7f19196745f",
   "metadata": {},
   "source": [
    "Compute *median*, *mean*, and *standard deviation* of the spectral signatures of the training samples from **pansharpened PRISMA**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d47ee-f5b1-49a9-b20f-3af1a35a0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_sign_median_s, spectral_sign_std_s = compute_spectral_signature(selected_prisma_pan_image, legend, shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247b787d-0271-4618-9f77-7d15d3b6d870",
   "metadata": {},
   "source": [
    "Select the LCZ classes of interest. The median spectral signature, as well as the +/- standard deviation interval for the selected classes will be displayed in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d338fa20-6488-42e9-be2c-9faa4f5f3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCZ_names = [value[0] for value in legend.values()]\n",
    "checkboxes = [widgets.Checkbox(value=True, description=str(LCZ)) for LCZ in LCZ_names]\n",
    "output = widgets.VBox(children=checkboxes)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658fc1e-96a2-4525-b987-99089abb3b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_LCZ_names = [checkbox.description for checkbox in checkboxes if checkbox.value]\n",
    "selected_classes = [key for key, value in legend.items() if value[0] in selected_LCZ_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ce77f-9a2f-4cf2-9d41-0bb4d48e9213",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectral_sign_comparison(wvl, spectral_sign_median, spectral_sign_median_s, legend, selected_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e9dd4-cde2-4013-add1-777eb6cbd2e9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "## <a id='sec4'></a>&#x27A4; 4. Quantitative assessment of the pansharpening quality: quality indexes computation\n",
    "\n",
    "[Back to top](#TOC_TOP)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04df14e",
   "metadata": {},
   "source": [
    "In this part some metrics are calculated to quantitatively assess the quality of the pansharpened images, following the **reduced resolution (RR)** approach, according to the *Wald's protocol*.\n",
    "RR approach measures the similarity of the fused product to an ideal reference, namely the original HS image.\n",
    "Accordingly, the resolutions of the original HS and PAN images are degradated and the fusion is performed on the degraded data.\n",
    "\n",
    "The following quality measures are used:\n",
    "1. *Spectral Angle Mapper (SAM)* that measures spectral quality;\n",
    "2. *Erreur Relative Globale Adimensionnelle de Synthése (ERGAS)* which is a global adimensional quality index based on the RMSE;\n",
    "3. *Spatial Correlation Coefficient (SCC)* that measure spatial quality;\n",
    "4. *Peak Signal-to-Noise Ratio (PSNR)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074ea06",
   "metadata": {},
   "source": [
    "The first step is to degrade the both the hyperspectral and the panchromatic bands by a factor of 6 (which is the ratio between the spatial resolution of the hyperspectral and panchromatic images). Accodingly, it is necessary to set the metadata of the degraded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a6eda-7ab9-4bc8-9a2e-805baac619db",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrade_resolution_factor = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebddfbf9-0cf6-410e-9340-a837e1a0bc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metadata of the original hyperspectral image (VNIR bands)\n",
    "hs_data_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3fc62-a198-4b4c-9c5c-1eef9baa572f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metadata of the pansharpened image\n",
    "pansharpened_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a028bba-bedf-49f2-9225-55be4f6ea0f6",
   "metadata": {},
   "source": [
    "Metadata of the degraded hyperspectral image (VNIR bands):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7093e57-89dc-4e2d-abb3-67e3031f46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_data_degraded_meta = hs_data_meta.copy()\n",
    "hs_data_degraded_meta.update({\n",
    "    'height': int(src_hs.height / degrade_resolution_factor),\n",
    "    'width': int(src_hs.width / degrade_resolution_factor),\n",
    "    'transform': rio.Affine(src_hs.transform[0] * degrade_resolution_factor, 0, src_hs.bounds.left, \n",
    "                            0, - (src_hs.transform[0] * degrade_resolution_factor), src_hs.bounds.top),\n",
    "    'count': n_bands\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30bb70-daeb-4e01-b49f-e83786807d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_data_degraded_meta #metadata of the downgraded hs image (30x6 m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d6047-70ee-4b68-8a66-8ff33500c6d6",
   "metadata": {},
   "source": [
    "Metadata of the degraded panchromatic image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101747d3-0c5e-4868-9db4-5c211125a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set metadata of the degraded pan image\n",
    "pan_data_degraded_meta = pansharpened_meta.copy()\n",
    "pan_data_degraded_meta.update({\n",
    "    'height': int(src_pan.height / degrade_resolution_factor),\n",
    "    'width': int(src_pan.width / degrade_resolution_factor),\n",
    "    'transform': rio.Affine(src_pan.transform[0] * degrade_resolution_factor, 0, src_pan.bounds.left, \n",
    "                            0, - (src_pan.transform[0] * degrade_resolution_factor), src_pan.bounds.top),\n",
    "    'dtype' : 'float32',\n",
    "    'count': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db55cd-b01d-43fe-ae36-597af9b29681",
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_data_degraded_meta #metadata of the downgraded pan image (5x6 m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63164f8b-cea5-4c70-9f29-32ab0e3a856c",
   "metadata": {},
   "source": [
    "Now it is possible to actually downscale the hyperspectral and panchromatic bands and save them to GeoTIFF files. First select the downsampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e196d-4824-49d8-9028-a160b2a7e994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resampling_methods = { \"nearest\": Resampling.nearest,\n",
    "                      \"bilinear\": Resampling.bilinear,\n",
    "                      \"cubic\": Resampling.cubic,\n",
    "                      \"cubic_spline\": Resampling.cubic_spline,\n",
    "                      \"lanczos\": Resampling.lanczos,\n",
    "                      \"average\": Resampling.average\n",
    "}\n",
    "\n",
    "resampling_methods_list = list(resampling_methods.keys())\n",
    "\n",
    "resampling_w = widgets.Dropdown(\n",
    "    options=resampling_methods_list,\n",
    "    value='bilinear',\n",
    "    description='Method:',\n",
    "    disabled=False,\n",
    ")\n",
    "resampling_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e35bb7-d1e7-4aaa-8629-4e888f3a2a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "degraded_hs_path = prisma_path + 'validation/' + 'hs_degraded_180m.tif'\n",
    "hs_data_degraded = resample_image(hs_data, hs_data_meta, hs_data_degraded_meta, degraded_hs_path, resampling_methods[resampling_w.value])\n",
    "print(f\"Resampling of HS image using {resampling_w.value} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775fa6dd-0b5f-48b6-9d0f-e591d152db24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "degraded_pan_path = prisma_path + 'validation/' + 'pan_degraded_30m.tif'\n",
    "pan_data_degraded = resample_image(pan_data, pan_data_meta, pan_data_degraded_meta, degraded_pan_path, resampling_methods[resampling_w.value])\n",
    "print(f\"Resampling of PAN image using {resampling_w.value} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9599957-dbad-4be8-8cb3-ca96bc00e7eb",
   "metadata": {},
   "source": [
    "Before applying again the pansharpening methods, the degraded hyperspectral image has to be resampled to match the number of pixels of the degraded panchromatic image (using the same interpolation method as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320427f-ea8e-4234-a4e5-bdc67687a8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dst_meta = pan_data_degraded_meta.copy()\n",
    "dst_meta['count'] = n_bands\n",
    "dst_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b53617-fd1c-4899-ab00-773b00d11004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "degraded_hs_upsampled_path = prisma_path + 'validation/' + 'hs_degraded_upsampled_30m.tif'\n",
    "hs_data_degraded_upsampled = resample_image(hs_data_degraded, hs_data_degraded_meta, dst_meta, degraded_hs_upsampled_path, resampling_methods[resampling_w.value])\n",
    "print(f\"Resampling of HS image using {resampling_w.value} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07889b60-3e88-4a1b-842d-410cc08ac8a2",
   "metadata": {},
   "source": [
    "Apply again the same pansharpening methods to the two downgraded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2640d9bf-394b-4484-b46c-8e821fd626c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if sw.value == 'Principal Component Analysis':\n",
    "    pansharpened, variance_ratios, pc_comp = pan_pca(pan_data_degraded, hs_data_degraded_upsampled)\n",
    "    with rio.open(prisma_path + 'validation/' + 'pansharpened_PCA_validation.tif', 'w', **dst_meta) as dst:\n",
    "        dst.write(pansharpened)\n",
    "elif sw.value == 'Gram-Schmidt':\n",
    "    pansharpened = pan_GS(pan_data_degraded, hs_data_degraded_upsampled)\n",
    "    with rio.open(prisma_path + 'validation/' + 'pansharpened_GS_validation.tif', 'w', **dst_meta) as dst:\n",
    "        dst.write(pansharpened)\n",
    "elif sw.value == 'Gram-Schmidt Adaptive':\n",
    "    pansharpened = pan_GSA(pan_data_degraded, hs_data_degraded, hs_data_degraded_upsampled, 'local')\n",
    "    with rio.open(prisma_path + 'validation/' + 'pansharpened_GSA_validation.tif', 'w', **dst_meta) as dst:\n",
    "        dst.write(pansharpened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f5ac4a",
   "metadata": {},
   "source": [
    "#### 1. Spectral Angle Mapper (SAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a4ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The optimum value is 0.\")\n",
    "print(f\"SAM applied on {sw.value} pansharpened image: {sam(pansharpened, hs_data):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86191c5e",
   "metadata": {},
   "source": [
    "#### 2. Erreur Relative Globale Adimensionnelle de Synthése (ERGAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963cb35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The optimum value is 0.\")\n",
    "print(f\"ERGAS applied on {sw.value} pansharpened image: {ergas(pansharpened, hs_data):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cbf17e",
   "metadata": {},
   "source": [
    "#### 3. Spatial Correlation Coefficient (SCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab20da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The optimum value is 1.\")\n",
    "print(f\"SCC applied on {sw.value} pansharpened image: {scc(pansharpened, hs_data):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee998f8",
   "metadata": {},
   "source": [
    "#### 4. Peak Signal-to-Noise Ratio (PSNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3e28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Higher PSNR is better.\")\n",
    "print(f\"PSNR applied on {sw.value} pansharpened image: {qindex(pansharpened, hs_data):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1ce6e8-37fe-43bd-9a5b-25a56b9f39ed",
   "metadata": {},
   "source": [
    "#### 5. Spectral Distorsion Index (D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08593b21-377e-4f46-8d9c-6fffb2e2b705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"D lambda applied on {sw.value} pansharpened image: {D_lambda(image_pansharpened, hs_data):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe49e96-5042-46f9-b258-5667a6f513fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
