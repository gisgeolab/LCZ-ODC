{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4855abfd-05fc-4705-9af1-229b72795ac1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<u><strong>Authors:</strong></u> <b>Alberto Vavassori</b> (alberto.vavassori@polimi.it), <b>Emanuele Capizzi</b> (emanuele.capizzi@polimi.it) - DICA - Politecnico di Milano - GIS GEOLab <br>\n",
    "Developed within the LCZ-ODC project, funded by the Italian Space Agency (agreement n. 2022-30-HH.0).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656c4a0-cec3-40d1-a79a-15926fc2733f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LCZ classification accuracy assessment\n",
    "\n",
    "<a id='TOC_TOP'></a>\n",
    "Notebook structure:  <br>\n",
    "\n",
    "[Part 1: Classification accuracy on testing samples](#sec1.0)\n",
    "\n",
    " 1. [Import testing samples](#sec1)  \n",
    " 2. [Rasterize testing samples](#sec2)\n",
    " 3. [Import the classified image to be assessed](#sec3)\n",
    " 4. [Assess classification accuracy on testing samples](#sec4)\n",
    " \n",
    "[Part 2: Inter-comparison with LCZ Generator product](#sec2.0)\n",
    "\n",
    " 5. [Accuracy of LCZ Generator product](#sec5)\n",
    " 6. [Extraction of samples for inter-comparison](#sec6)\n",
    " 7. [Computation of confusion matrix and consistency metrics](#sec7)\n",
    " \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a04da65-b54a-4ade-a1b0-3196f07805a9",
   "metadata": {},
   "source": [
    "This Notebook is meant to verify the quality of the classification using testing samples. These samples consist of an external dataset that was not used within the classification step. The testing samples are always defined by the user and can be imported into this Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b49997-9f8f-4b95-a92b-66b0e5b35c9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc262695-734b-4fdd-9870-ded7709edefd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "Note: the Notebook relies on the <a href='https://gdal.org/' target='_blank'><em>gdal</em></a> Python library; make sure you have it installed in your environment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c5c67-31a3-4067-88bf-7830cbc3644d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.windows import Window\n",
    "from rasterio.enums import Resampling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from osgeo import gdal, ogr, gdalconst, gdal_array, osr\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951322b5-4e4d-449e-9cff-0d6ad1819dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import functions and set auto-reload\n",
    "from functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f7251-18e6-48ae-b939-91c91a9b1dac",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "# <a id='sec1.0'></a> Part 1: Classification accuracy on testing samples\n",
    "<a id='sec2'></a>\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d6052-2d61-4133-8844-30544712f59c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. <a id='sec1'></a> Import testing samples\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49bc38-ad56-41e8-b442-2c55749abf63",
   "metadata": {},
   "source": [
    "First, select the PRISMA image date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d5b77-2919-4c7f-a4f6-041362ee60e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_prisma_w = widgets.Dropdown(\n",
    "    options=['2023-02-09', '2023-03-22', '2023-04-08', '2023-06-17', '2023-07-10', '2023-08-08'],\n",
    "    value='2023-02-09',\n",
    "    description='PRISMA date:',\n",
    "    disabled=False,\n",
    "    layout={'width': 'max-content'},\n",
    "    style = {'description_width': 'initial'}\n",
    ")\n",
    "date_prisma_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde817e6-b9ba-4c57-a070-63a542bd3a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel_prisma_date = date_prisma_w.value\n",
    "selected_prisma_image = 'PRISMA_outputs/coregistered/PR_'+ sel_prisma_date.replace('-', '') + '_30m.tif'\n",
    "print(f\"The selected date is --> PRISMA: {sel_prisma_date}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17155a-b39a-495b-9c40-e7f472d946a3",
   "metadata": {},
   "source": [
    "Set the legend that will be used henceforth for the plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e73544-d0ed-473a-ab01-d862e592f504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "legend = {\n",
    "    2: ['Compact mid-rise', '#D10000'],\n",
    "    3: ['Compact low-rise', '#CD0000'],\n",
    "    5: ['Open mid-rise', '#FF6600'],\n",
    "    6: ['Open low-rise', '#FF9955'],\n",
    "    8: ['Large low-rise', '#BCBCBC'],\n",
    "    101: ['Dense trees', '#006A00'],\n",
    "    102: ['Scattered trees', '#00AA00'],\n",
    "    104: ['Low plants', '#B9DB79'],\n",
    "    105: ['Bare rock or paved', '#545454'],\n",
    "    106: ['Bare soil or sand', '#FBF7AF'],\n",
    "    107: ['Water', '#6A6AFF']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd354c67-f882-4328-9b1e-8837f4005943",
   "metadata": {},
   "source": [
    "The following function displays the testing samples on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56d8df-147f-423b-8271-651ab0521f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_folder = './layers/testing_samples/testing_set_' + sel_prisma_date.replace('-', '') + '.gpkg'\n",
    "cmm_folder = './layers/CMM.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ea226-9736-477d-8981-84bc43e1a8ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing, m, shapes = plot_training_samples(testing_folder, cmm_folder, legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c6abc-eb82-4680-b0a1-27f52a874dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb65ca-5c9f-4b37-b9d4-d504e5c457f7",
   "metadata": {},
   "source": [
    "The following function imports the testing samples and computes the area of each LCZ class. The function outputs a plot with the total area of each LCZ class as well as the path to the vector layer that will be used in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b1ce2a-90e6-453c-a6b2-b9936babcd73",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> \n",
    "\n",
    "**Note**:\n",
    "Testing samples must be stored in `.gpkg` format as vector multi-polygons, and the file must contain a column `LCZ` with integer values corresponding to the LCZ class, as reported in the dictionary `legend`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3769b87b-7265-4d69-abda-560ca1a76df2",
   "metadata": {},
   "source": [
    "</div>\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> Testing samples are time-dependent, especially for the natural classes; they must be updated if there are changes (e.g. in the land cover).  The following function imports the training samples specific to the selected PRISMA acquisition date.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df579028-f388-4287-b083-c767461f8759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_LCZ_path = testing_area(sel_prisma_date, legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3b2e3-3a95-4456-83bf-efd887b8e2de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. <a id='sec2'></a>Rasterize testing samples\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57aef21-af9a-4c95-b46a-d60daa961dd5",
   "metadata": {},
   "source": [
    "</div>\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> If testing samples are already rasterized, skip this section and go to the next one.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f590ffa6-2b88-40f2-9a82-10142de97387",
   "metadata": {},
   "source": [
    "It is necessary to convert the testing set (provided in vector format as Geopackage) in raster format using the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d58c7d-f3ba-445f-b427-cbb909890635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raster_reference = 'PCs/PCs_'+ sel_prisma_date.replace('-', '') +'_30m.tif'\n",
    "output = './layers/testing_samples/testing_set_'+ sel_prisma_date.replace('-', '') + '_30m.tif'\n",
    "attribute = 'LCZ'\n",
    "projection = 32632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a55cd6-d0d1-4c56-b5b3-357dfbf4c0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rasterized_result = rasterize_training('PCs/PCs_' + sel_prisma_date.replace('-', '') + '_30m.tif', vector_LCZ_path, output, attribute, projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85022c9-a147-418a-ac04-ff44c3834d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_raster_training(output, legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b7f24-22e6-49b8-835c-40eedb559be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bbox = prisma_bbox(selected_prisma_image, sel_prisma_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf9b37-0e3b-4270-b4de-d9753fa3a12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_prisma = mask_prisma_image(selected_prisma_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2bcb7-ced9-4311-9df3-22ac3e28d304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_area = gpd.read_file(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fb42f-c325-48fc-9d2b-60b6b3b21ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roi_ds = './layers/testing_samples/testing_set_'+ sel_prisma_date.replace('-', '')+'_30m.tif'\n",
    "roi_new_path = './layers/testing_samples/testing_set_'+ sel_prisma_date.replace('-', '')+'_30m.tif'\n",
    "clip_image_study_area(roi_ds, roi_new_path, study_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee727c-4ecf-4ef6-bda5-231c110ab764",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. <a id='sec3'></a>Import the classified image to be assessed\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f51df-7224-482a-bbe3-729ba55feddd",
   "metadata": {},
   "source": [
    "Select the method used for classification to chose the image that want to be tested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201456d-3213-4ab3-9a8a-0006d432141d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classification_method_w = widgets.RadioButtons(\n",
    "    options=['RandomForest', 'XGBoost', 'AdaBoost', 'GradientBoost'],\n",
    "    value='RandomForest',\n",
    "    layout={'width': 'max-content'},\n",
    "    description='Classifier:',\n",
    "    disabled=False\n",
    ")\n",
    "classification_method_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507177b4-9097-4746-a434-6b6852b7bb28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classification_method = classification_method_w.value\n",
    "print(f'Selected classification method: {classification_method}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a4135d-0537-4135-8ae0-caf847eec338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Selected image: classified_images/classified_' + classification_method + '_' + sel_prisma_date.replace('-', '') + '_medianfilter_30m.tif')\n",
    "classified_image = rasterio.open('classified_images/classified_' + classification_method + '_' + sel_prisma_date.replace('-', '') + '_medianfilter_30m.tif')\n",
    "classified_image = classified_image.read()\n",
    "print(f\"Selected image shape: {classified_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d6b4d-8abd-4308-8785-bc567d86b12a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_classified_image(sel_prisma_date, classified_image, classification_method, legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e182b231-83d8-4dc0-a0ff-b15e2ff65099",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. <a id='sec4'></a>Assess classification accuracy on testing samples\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c799b5a2-178a-4ead-9b01-44ae6c981c4a",
   "metadata": {},
   "source": [
    "In this section, some accuracy metrics are computed on the testing samples, specifically:\n",
    "* accuracy: overall accuracy of the model, i.e. the fraction of the total samples that were correctly classified\n",
    "\n",
    "$$ \\frac{TP+TN}{TP+TN+FP+FN} $$\n",
    "\n",
    "* precision: fraction of predictions as a positive class were actually positive\n",
    "\n",
    "$$ \\frac{TP}{TP+FP} $$\n",
    "\n",
    "* recall: fraction of all positive samples that are correctly predicted as positive\n",
    "\n",
    "$$ \\frac{TP}{TP+FN} $$\n",
    "\n",
    "* f1-score: combination of precision and recall; mathematically it is the harmonic mean of precision and recall\n",
    "\n",
    "$$\\frac{2(precision*recall)}{precision+recall}$$\n",
    "\n",
    "* support: number of occurrences of each class in the testing sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f3667-ea34-4795-be3c-820a5e00d202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy, confusion, report, report_df = print_accuracy(classification_method, sel_prisma_date, legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1112d2a0-aea0-4f69-ba09-39b541b732e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd37a4-e9b4-4bb8-92ce-309f48e1139e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd019665-aa5c-46fa-9dca-fbcc8dfd8cf8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "# <a id='sec2.0'></a> Part 2: Inter-comparison with LCZ Generator product\n",
    "<a id='sec2'></a>\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad166a0e-26a8-405d-b625-cf85effef806",
   "metadata": {},
   "source": [
    "## 5. <a id='sec5'></a> Accuracy of LCZ Generator product\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f948a564-12f5-4f48-9aa5-22e0965d21a0",
   "metadata": {},
   "source": [
    "The accuracy of the LCZ Generator product is evaluated internally, and it is provided as output. Here we read the confusion matrix from the csv file, and we compute accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b6c62-447a-4613-b3ca-4e2936d257db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#directory = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/data/*cm_average_formatted.csv'\n",
    "#confusion_matrix_path = glob.glob(directory)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9206bf6-d26e-4f38-8857-7f9ab6d44c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#report = lcz_generator_accuracy(confusion_matrix_path, legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6925febc-42dc-4bb4-8a98-3ca7f44ea86b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. <a id='sec6'></a>Extraction of samples for inter-comparison with LCZ Generator product\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c37207-823c-4153-b6b4-f154abc46430",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "This section needs some pre-processing that can be performed entirely in QGIS. Specifically:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed596da-fc9c-424d-ba1c-c4a4fe55e684",
   "metadata": {},
   "source": [
    "* The two maps have to be resampled to 10m resolution in QGIS, given that they have different spatial resolution (100m and 30m).\n",
    "* The LCZ Generator map must be aligned to the PRISMA map.\n",
    "* The two classified maps must finally be post-processed with a median filter of 9 pixels (the size is coherent with the 3 pixel window size that is used for post-processing the PRISMA map in the LCZ-ODC project workflow).\n",
    "* Finally, the LCZ Generator map must be reclassified so that the LCZ classes are encoded as in the PRISMA map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb228b-1aa4-466e-94f7-bd0a0e3c1e2f",
   "metadata": {},
   "source": [
    "Once the above pre-processing is done, clip the LCZ Generator map to the extent of the PRISMA map (this is crucial because the PRISMA map is rotated with respect to the other one due to the acquisition mode of the satellite)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90687c-3abc-4c0f-82b7-69b48cf9befa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths to your input rasters (pre-processed in QGIS)\n",
    "lcz_generator_map_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/lcz_generator_map_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass.tif'\n",
    "prisma_map_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/prisma_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51529966-11fd-45d8-ae88-e86402a286f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rasterio.open(lcz_generator_map_path) as src1:\n",
    "    lcz_generator_map = src1.read()\n",
    "    lcz_generator_map_profile = src1.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3b821-c158-4d27-b7fe-ff8a7c9626b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rasterio.open(prisma_map_path) as src2:\n",
    "    prisma_map = src2.read()\n",
    "    prisma_map_profile = src2.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd1ceb7-ecb2-4b41-b803-4e532f6b36b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prisma_map[prisma_map < 0] = np.nan\n",
    "nan_indices = np.isnan(prisma_map)\n",
    "lcz_generator_map[nan_indices] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45efd2-dce4-424a-8c90-f66d196e8212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rasterio.open('./layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/lcz_generator_map_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass_clip.tif', 'w', **lcz_generator_map_profile) as dst:\n",
    "    dst.write(lcz_generator_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0f0fa-0041-4c86-9401-d77ce5cd5a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rasterio.open('./layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/prisma_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass.tif', 'w', **lcz_generator_map_profile) as dst:\n",
    "    dst.write(prisma_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fdf895-1eda-4234-91eb-92776bdad521",
   "metadata": {},
   "source": [
    "The inter-comparison is hereafter carried out following 3 sampling schemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d5fb5-df6c-44df-9461-81eb6d7df354",
   "metadata": {},
   "source": [
    "<u>Sampling schema: random sampling with fixed pixel number<u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008f112-040d-494c-90ae-f3df41701bda",
   "metadata": {},
   "source": [
    "This first sampling schema considers a fixed number of pixels, calculated using the Cochran's formula for large populations.\n",
    "Considering a precision level of +/-3%, a confidence level of 98%, and an estimated proportion of 0.5, the appropriate sample size is about 1500.\n",
    "In the random sampling, the same number of pixels is extracted out of each class, equal to 1500/n (n being the number of classes). In this case, n = 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce4de5-a361-4623-9496-ae56eab448e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raster1_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/lcz_generator_map_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass_clip.tif'\n",
    "raster2_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/prisma_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ac447-77ff-4836-a847-78ae4120628f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_raster1_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/lcz_generator_map_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass_clip_pixels.tif'\n",
    "output_raster2_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/prisma_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass_pixels.tif'\n",
    "output_raster3_path = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c72947-e28c-4777-b25d-c0a200483447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pixels_number = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf5927-04d8-493c-b586-360e3c5bca0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_sampling(raster1_path, raster2_path, output_raster1_path, output_raster2_path, pixels_number, legend.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ebf16e-1dec-40ea-adc7-9fc0588f689f",
   "metadata": {},
   "source": [
    "<u>Sampling schema: stratified random sampling with fixed pixel number<u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da0114f-ba63-4689-924e-ecb008010d95",
   "metadata": {},
   "source": [
    "A second sampling schema considers a fixed number of total pixels, calculated using the Cochran's formula for large populations, and subdivides it to each class (or stratum) according to its size (number of pixels). Considering a precision level of +/-3%, a confidence level of 98%, and an estimated proportion of 0.5, the appropriate sample size is about 1500. In the stratified random sampling, the number of pixels to be extracted per class is computed as:\n",
    "\n",
    "$$ n_h = \\frac{N_h}{N} n $$\n",
    "\n",
    "where $n_h$ is the sample size of the h-th class, $N_h$ is the population size of the h-th class, $N$ is the size of the entire population (number of pixels in the raster, excluding nans) and $n$ is the size of the entire sample (1500)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a603c-3597-4bfa-bc99-7f200b657fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raster1_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/lcz_generator_map_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass_clip.tif'\n",
    "raster2_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/prisma_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a286ee-bfef-447d-bc1a-3c465ba25d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_raster1_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/lcz_generator_map_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass_clip_pixels_strat.tif'\n",
    "output_raster2_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/prisma_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass_pixels_strat.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8106cb6d-157f-441e-a447-c63b07e52444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n: size of the entire sample\n",
    "n = 1500\n",
    "pixels_number = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d6db50-a0b3-405e-ba9b-cdc9807a55d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stratified_sampling(raster1_path, raster2_path, output_raster1_path, output_raster2_path, pixels_number, legend.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6af332-4dd3-46cb-b907-ec618572791a",
   "metadata": {},
   "source": [
    "<u>Sampling schema: take all pixels of the maps<u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da304698-dd35-4db6-8b6d-337f4ff52286",
   "metadata": {},
   "source": [
    "A third possibility consists in using all the pixels of both rasters for the comparison. If this is the case, just put as input in the below function to outputs of the first pre-processing, namely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a24d3-97aa-48dc-a788-fe7c4af51505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raster1_path = './layers/lcz_generator/comparison_20230209/lcz_generator_map_20230209_10m_align_medianfilter9_reclass_clip.tif'\n",
    "# raster2_path = './layers/lcz_generator/comparison_20230209/prisma_20230209_10m_align_medianfilter9_reclass.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb55033c-7940-48f5-851e-68b5c0c1c72b",
   "metadata": {},
   "source": [
    "## 7. <a id='sec7'></a>Computation of confusion matrix and consistency metrics\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d5eaf-3608-4b7a-9fca-044fb54a1230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_raster_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/lcz_generator_map_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass_clip_pixels.tif'\n",
    "raster_path = './layers/lcz_generator/comparison_' + sel_prisma_date.replace('-', '') + '/prisma_' + sel_prisma_date.replace('-', '') + '_10m_align_medianfilter9_reclass_pixels.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbae10c-0c75-41a6-a32a-8785cfa8535d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy, confusion, report, report_df = inter_comparison(raster_path, ref_raster_path, legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75825749-6c0d-46ea-a354-a14cdf791601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe493c2f-291e-4f6e-a2ce-ce592623f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e4473-f86b-4887-99ba-a10ffeb4e3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9ed50-8f01-477c-b558-0ff6252567a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0424ee2-f50a-41d2-8afb-1be762793424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347f9b4-a4f8-43d5-b53e-05ede136f14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6224f-b43b-4e7e-9532-8ceb2408e1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66731028-d09b-45ce-b03b-e6fccdfd043b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce67ef6-5a7d-47fe-a537-2eb7c112d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################INTER-COMPARISON WITH LCZ-GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6fe34-a5c8-45d6-bf0f-370bdd09d9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classi = [\"Compact Mid-rise\",\"Compact Low-rise\",\"Open Mid-rise\",\"Open Low-rise\",\"Large Low-rise\",\n",
    "          \"Dense trees\",\"Scattered trees\",\"Low plants\",\"Bare rock or paved\",\"Bare soil or sand\",\"Water\"]\n",
    "\n",
    "accur_prisma_9feb = np.array([[1229,   23,   73,    0,    8,    0,    0,    0,    0,    0,    0],\n",
    "       [ 114,  785,   75,   92,    4,    0,    0,    0,    0,    0,    0],\n",
    "       [ 125,   37,  970,   23,    0,    0,    0,    0,    0,    0,    0],\n",
    "       [   0,  176,   81,  864,    0,    0,   19,    0,   15,    0,    0],\n",
    "       [   0,    0,    0,    1, 1169,    0,    0,    0,    0,    0,    0],\n",
    "       [   0,    0,    1,    7,    0,  912,  242,    0,    0,    0,    0],\n",
    "       [   2,    0,    8,   22,    6,   46, 1149,    0,    4,    0,    0],\n",
    "       [   0,    0,    0,    0,    0,    0,    8, 1212,    0,    0,    0],\n",
    "       [   0,    0,    0,    0,    0,    0,    4,    1,  296,    1,    0],\n",
    "       [   0,    0,    0,    0,    6,    0,    0,    1,    0, 1233,    0],\n",
    "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  643]])\n",
    "accur_prisma_9feb = accur_prisma_9feb / np.sum(accur_prisma_9feb)*100\n",
    "\n",
    "accur_prisma_17jun = np.array([[1187,   17,  133,    0,    4,    0,    0,    0,    0,    0,    0],\n",
    "       [  82,  779,   70,  126,   11,    0,    0,    0,    0,    0,    0],\n",
    "       [ 186,   26,  904,   35,    2,    0,    0,    0,    0,    0,    0],\n",
    "       [   1,  185,   46,  898,    0,    0,   14,    0,    2,    1,    0],\n",
    "       [   0,    2,    9,    1, 1160,    0,    0,    0,    0,    1,    0],\n",
    "       [   0,    0,    1,    7,    0,  626,  218,    5,    0,    0,    0],\n",
    "       [   0,    0,    4,   29,    2,   10, 1147,   22,   21,    5,    0],\n",
    "       [   0,    0,    0,    0,    0,    0,    2, 1650,    0,  139,    1],\n",
    "       [   0,    0,    0,    4,    0,    0,    0,    1,  315,    6,    0],\n",
    "       [   0,    0,    0,    0,    2,    0,    0,    5,    0, 1302,    0],\n",
    "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  648]])\n",
    "accur_prisma_17jun = accur_prisma_17jun / np.sum(accur_prisma_17jun)*100\n",
    "\n",
    "accur_prisma_8aug = np.array([[1177,   42,  114,    0,    4,    0,    0,    0,    0,    0,    0],\n",
    "       [  65,  664,  103,   45,   28,    0,    0,    0,    0,    0,    0],\n",
    "       [ 188,   20,  923,   17,    0,    0,    0,    0,    0,    0,    0],\n",
    "       [   0,  168,  142,  630,    1,    0,   17,    0,   12,    0,    0],\n",
    "       [   0,    5,   18,    2, 1147,    0,    0,    1,    0,    0,    0],\n",
    "       [   0,    0,    3,    7,    0,  215,  320,    1,    0,    0,    0],\n",
    "       [   0,    0,    8,   21,    3,   85, 1132,   37,    3,    0,    4],\n",
    "       [   0,    0,    0,    0,    0,    0,    4, 2307,    0,   56,    0],\n",
    "       [   0,    0,    0,    1,   13,    0,    3,    0,  576,    1,    0],\n",
    "       [   0,    0,    0,    0,   12,    0,    0,    8,    4, 1104,    0],\n",
    "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  521]])\n",
    "accur_prisma_8aug = accur_prisma_8aug / np.sum(accur_prisma_8aug)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d98eff-2343-46c6-b6c3-2e322a0dbee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Create a DataFrame from the matrix\n",
    "accuracy_prisma = pd.DataFrame(data = accur_prisma_9feb)\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax1 = plt.subplots(figsize=(10, 10))\n",
    "plt.tight_layout()\n",
    "\n",
    "#cbar_ax = f.add_axes([0.25, 0.01, 0.5, 0.02])  # Adjust the position and size as needed\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "#cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "cmap = 'Greens'\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(accur_prisma_9feb, ax = ax1, cmap=cmap, vmin = 0, vmax = 14,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5, \"use_gridspec\": True}, #, \"orientation\": \"horizontal\"\n",
    "            annot=True, fmt=\".1f\", annot_kws={\"fontsize\": 13, \"color\": 'black'}) #, cbar_ax = cbar_ax\n",
    "\n",
    "# Set x and y ticks\n",
    "ax1.set_xticks(np.arange(len(classi)) + 0.5)\n",
    "ax1.set_yticks(np.arange(len(classi)) + 0.5)\n",
    "ax1.set_ylabel(\"Testing samples\", fontsize = 15)\n",
    "ax1.set_xlabel(\"PRISMA map\", fontsize = 15)\n",
    "\n",
    "# Set x and y tick labels\n",
    "ax1.set_xticklabels(classi, rotation = 90, ha = \"right\", fontsize = 15)\n",
    "ax1.set_yticklabels(classi, rotation = 0, va = \"center\", fontsize = 15)\n",
    "ax1.set_title('Confusion matrix computed from testing samples\\nPRISMA', fontweight = 'bold', fontsize = 15)\n",
    "\n",
    "plt.subplots_adjust(left = 0.30, right = 0.9, bottom = 0.2, top = 0.9)\n",
    "plt.savefig('classified_images/accuracy_prisma_feb_test_samples.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac6da9-d0ce-493d-946d-674868de85e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Create a DataFrame from the matrix\n",
    "accuracy_prisma = pd.DataFrame(data = accur_prisma_17jun)\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax1 = plt.subplots(figsize=(10, 10))\n",
    "plt.tight_layout()\n",
    "\n",
    "#cbar_ax = f.add_axes([0.25, 0.01, 0.5, 0.02])  # Adjust the position and size as needed\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "#cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "cmap = 'Greens'\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(accur_prisma_17jun, ax = ax1, cmap=cmap, vmin = 0, vmax = 14,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5, \"use_gridspec\": True}, #, \"orientation\": \"horizontal\"\n",
    "            annot=True, fmt=\".1f\", annot_kws={\"fontsize\": 13, \"color\": 'black'}) #, cbar_ax = cbar_ax\n",
    "\n",
    "# Set x and y ticks\n",
    "ax1.set_xticks(np.arange(len(classi)) + 0.5)\n",
    "ax1.set_yticks(np.arange(len(classi)) + 0.5)\n",
    "ax1.set_ylabel(\"Testing samples\", fontsize = 15)\n",
    "ax1.set_xlabel(\"PRISMA map\", fontsize = 15)\n",
    "\n",
    "# Set x and y tick labels\n",
    "ax1.set_xticklabels(classi, rotation = 90, ha = \"right\", fontsize = 15)\n",
    "ax1.set_yticklabels(classi, rotation = 0, va = \"center\", fontsize = 15)\n",
    "ax1.set_title('Confusion matrix computed from testing samples\\nPRISMA', fontweight = 'bold', fontsize = 15)\n",
    "\n",
    "plt.subplots_adjust(left = 0.30, right = 0.9, bottom = 0.2, top = 0.9)\n",
    "plt.savefig('classified_images/accuracy_prisma_jun_test_samples.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed5927-b918-4ae4-a2a0-0d805463ac63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
